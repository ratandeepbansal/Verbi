# voice_assistant/config.py

import os
from dotenv import load_dotenv

# Load environment variables from the .env file
load_dotenv()

class Config:
    """
    Configuration class to hold the model selection and API keys.

    Attributes:
        TRANSCRIPTION_MODEL (str): The model to use for transcription ('openai', 'groq', 'deepgram', 'fastwhisperapi', 'faster-whisper', 'local').
        RESPONSE_MODEL (str): The model to use for response generation ('openai', 'groq', 'ollama', 'lmstudio', 'local').
        TTS_MODEL (str): The model to use for text-to-speech ('openai', 'deepgram', 'elevenlabs', 'melotts', 'cartesia', 'piper', 'local').
        OPENAI_API_KEY (str): API key for OpenAI services.
        GROQ_API_KEY (str): API key for Groq services.
        DEEPGRAM_API_KEY (str): API key for Deepgram services.
        ELEVENLABS_API_KEY (str): API key for ElevenLabs services.
        CARTESIA_API_KEY (str): API key for Cartesia services.
        LOCAL_MODEL_PATH (str): Path to the local model.
        LMSTUDIO_BASE_URL (str): Base URL for LM Studio local server.
        FASTER_WHISPER_MODEL (str): Model size for faster-whisper.
    """
    # Model selection
    TRANSCRIPTION_MODEL = 'deepgram'  # possible values: openai, groq, deepgram, fastwhisperapi, faster-whisper
    RESPONSE_MODEL = 'openai'  # possible values: openai, groq, ollama, lmstudio
    TTS_MODEL = 'openai'  # possible values: openai, deepgram, elevenlabs, melotts, cartesia, piper

    # Piper Server configuration
    PIPER_SERVER_URL = os.getenv("PIPER_SERVER_URL")
    PIPER_OUTPUT_FILE = "output.wav"

    # currently using the MeloTTS for local models. here is how to get started:
    # https://github.com/myshell-ai/MeloTTS/blob/main/docs/install.md#linux-and-macos-install

    # LLM Selection
    OLLAMA_LLM="llama3:8b"
    GROQ_LLM="llama3-8b-8192"
    OPENAI_LLM="gpt-4o"

    # Local Models Configuration
    LMSTUDIO_BASE_URL = os.getenv("LMSTUDIO_BASE_URL", "http://localhost:1234")
    FASTER_WHISPER_MODEL = os.getenv("FASTER_WHISPER_MODEL", "base")  # Options: tiny, base, small, medium, large-v3

    # API keys and paths
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    GROQ_API_KEY = os.getenv("GROQ_API_KEY")
    DEEPGRAM_API_KEY = os.getenv("DEEPGRAM_API_KEY")
    ELEVENLABS_API_KEY = os.getenv("ELEVENLABS_API_KEY")
    LOCAL_MODEL_PATH = os.getenv("LOCAL_MODEL_PATH")
    CARTESIA_API_KEY = os.getenv("CARTESIA_API_KEY")

    # for serving the MeloTTS model
    TTS_PORT_LOCAL = 5150

    # temp file generated by the initial STT model
    INPUT_AUDIO = "test.mp3"

    @staticmethod
    def get_input_audio_path():
        """
        Get the path to the input audio file.
        This method exists for future migration to temp file manager.

        Returns:
            str: Path to input audio file
        """
        return Config.INPUT_AUDIO

    @staticmethod
    def load_from_file(config_file=".verbi_config.json"):
        """
        Load configuration from JSON file if it exists.

        Args:
            config_file: Path to the config file
        """
        import json

        if os.path.exists(config_file):
            try:
                with open(config_file, 'r') as f:
                    settings = json.load(f)

                # Update model selection
                if "transcription_model" in settings:
                    Config.TRANSCRIPTION_MODEL = settings["transcription_model"]
                if "response_model" in settings:
                    Config.RESPONSE_MODEL = settings["response_model"]
                if "tts_model" in settings:
                    Config.TTS_MODEL = settings["tts_model"]

                # Update LLM models
                if "openai_llm" in settings:
                    Config.OPENAI_LLM = settings["openai_llm"]
                if "groq_llm" in settings:
                    Config.GROQ_LLM = settings["groq_llm"]
                if "ollama_llm" in settings:
                    Config.OLLAMA_LLM = settings["ollama_llm"]

                # Update local model settings
                if "lmstudio_base_url" in settings:
                    Config.LMSTUDIO_BASE_URL = settings["lmstudio_base_url"]
                if "faster_whisper_model" in settings:
                    Config.FASTER_WHISPER_MODEL = settings["faster_whisper_model"]

                # Update API keys if provided
                if settings.get("openai_api_key"):
                    Config.OPENAI_API_KEY = settings["openai_api_key"]
                    os.environ["OPENAI_API_KEY"] = settings["openai_api_key"]
                if settings.get("groq_api_key"):
                    Config.GROQ_API_KEY = settings["groq_api_key"]
                    os.environ["GROQ_API_KEY"] = settings["groq_api_key"]
                if settings.get("deepgram_api_key"):
                    Config.DEEPGRAM_API_KEY = settings["deepgram_api_key"]
                    os.environ["DEEPGRAM_API_KEY"] = settings["deepgram_api_key"]
                if settings.get("elevenlabs_api_key"):
                    Config.ELEVENLABS_API_KEY = settings["elevenlabs_api_key"]
                    os.environ["ELEVENLABS_API_KEY"] = settings["elevenlabs_api_key"]
                if settings.get("cartesia_api_key"):
                    Config.CARTESIA_API_KEY = settings["cartesia_api_key"]
                    os.environ["CARTESIA_API_KEY"] = settings["cartesia_api_key"]

                return True
            except Exception as e:
                print(f"Error loading config file: {e}")
                return False
        return False

    @staticmethod
    def validate_config():
        """
        Validate the configuration to ensure all necessary environment variables are set.

        Raises:
            ValueError: If a required environment variable is not set.
        """
        Config._validate_model('TRANSCRIPTION_MODEL', [
            'openai', 'groq', 'deepgram', 'fastwhisperapi', 'faster-whisper', 'local'])
        Config._validate_model('RESPONSE_MODEL', [
            'openai', 'groq', 'ollama', 'lmstudio', 'local'])
        Config._validate_model('TTS_MODEL', [
            'openai', 'deepgram', 'elevenlabs', 'melotts', 'cartesia', 'local', 'piper', 'pyttsx3'])

        Config._validate_api_key('TRANSCRIPTION_MODEL', 'openai', 'OPENAI_API_KEY')
        Config._validate_api_key('TRANSCRIPTION_MODEL', 'groq', 'GROQ_API_KEY')
        Config._validate_api_key('TRANSCRIPTION_MODEL', 'deepgram', 'DEEPGRAM_API_KEY')

        Config._validate_api_key('RESPONSE_MODEL', 'openai', 'OPENAI_API_KEY')
        Config._validate_api_key('RESPONSE_MODEL', 'groq', 'GROQ_API_KEY')

        Config._validate_api_key('TTS_MODEL', 'openai', 'OPENAI_API_KEY')
        Config._validate_api_key('TTS_MODEL', 'deepgram', 'DEEPGRAM_API_KEY')
        Config._validate_api_key('TTS_MODEL', 'elevenlabs', 'ELEVENLABS_API_KEY')
        Config._validate_api_key('TTS_MODEL', 'cartesia', 'CARTESIA_API_KEY')

    @staticmethod
    def _validate_model(attribute, valid_options):
        model = getattr(Config, attribute)
        if model not in valid_options:
            raise ValueError(
                f"Invalid {attribute}. Must be one of {valid_options}"
            )
        
    @staticmethod
    def _validate_api_key(model_attr, model_value, api_key_attr):
        if getattr(Config, model_attr) == model_value and not getattr(Config, api_key_attr):
            raise ValueError(f"{api_key_attr} is required for {model_value} models")